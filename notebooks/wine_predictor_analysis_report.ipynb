{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864b43f9-fb3e-4c62-8f34-27607b772330",
   "metadata": {},
   "source": [
    "# Predicting wine quality given chemical characteristics of the wine\n",
    "by Yixuan Gao, Bryan Lee, Wangkai Zhu, Timothy Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f0bf5b-1c9c-4c15-9a84-1769a9be9e91",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a2580-8d32-4753-9f6f-edfaa03c23c1",
   "metadata": {},
   "source": [
    "This project aims to build a machine learning model to classify the quality of red wine based on its physicochemical properties. The target variable, wine quality, is scored on a scale from 0 (poor quality) to 10 (high quality), presenting a multi-class classification challenge. The dataset, sourced from the UC Irvine Machine Learning Repository, comprises 1,599 observations with 11 continuous features such as acidity, alcohol content, and citric acid.\n",
    "\n",
    "Four classification algorithms were evaluated: Logistic Regression, Decision Tree, K-Nearest Neighbors (KNN), Naive Bayes and Support Vector Machine with a Radial Basis Function kernel (SVM RBF). 5-fold cross-validation was used with training data to find the best classification algorithm, based on accuracy. Hyperparameter tuning was used to optimize the model and assess its generalization performance. The model with hyperparameters that gave the best accuracy was selected for deployment on the test set.\n",
    "\n",
    "By leveraging machine learning, this project seeks to provide a systematic and measurable way to predict wine quality, aiding manufacturers and suppliers in assessing product value based on its chemical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d0e5d6-2a56-4920-88d9-00b0df757794",
   "metadata": {},
   "source": [
    "## Introduction:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82e358-594c-408b-942f-ff71b3d0d85a",
   "metadata": {},
   "source": [
    "Red wine has been a cultural and economic staple since ancient times, originating from early civilizations like the Greeks and evolving into a global industry valued at approximately 109.5 billion USD. Despite its widespread availability, differentiating between high and low-quality wines remains a challenge for most consumers. Traditionally, this task has relied on the expertise of sommeliers, whose judgments are often subjective.\n",
    "\n",
    "This project aims to bridge the gap between subjective assessments and objective measurement by utilizing machine learning to predict wine quality. By analyzing the physicochemical properties of red wine—such as acidity, alcohol content, and sugar levels—we aim to classify its quality on a scale from 0 to 10.\n",
    "\n",
    "Using the Red Wine Quality Dataset from the UC Irvine Machine Learning Repository, we evaluate the performance of several classification algorithms: Logistic Regression, Decision Tree, KNN, Naive Bayes and SVM with an RBF kernel. Through hyperparameter tuning and cross-validation, the goal is to identify the most accurate model and demonstrate the practical application of data-driven decision-making in the wine industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62693e-32e5-43e7-8935-4595e036d381",
   "metadata": {},
   "source": [
    "## Methods & Results:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a9744-7a7f-4524-b8d3-1f9789629207",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82de10e8-e030-4403-97d9-4a8bbb93f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report,confusion_matrix,multilabel_confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b11b692-653d-49e6-a5ea-c61adf93c27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/winequality_red.csv', sep = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e50d3-eeee-495e-8d20-529b932c0a17",
   "metadata": {},
   "source": [
    "### Data Cleaning and Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6aae64b1-0926-4d7a-b87b-532b7013daaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c33f4bc-f4e9-4130-9a06-4eb3dfa0dcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49ba1e-3cb7-4aa8-8fb7-bfd30b66efca",
   "metadata": {},
   "source": [
    "A thorough examination of the dataset revealed no missing values in any of the columns. This was verified by checking for null entries in all rows and columns using methods such as isnull() and info() in Python. Since the dataset was complete, no imputation or removal of rows/columns was necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a90b3-112a-45be-9778-4b0d6e8561c5",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5191c10-9b88-47d1-9d29-711fef89725d",
   "metadata": {},
   "source": [
    "- fixed acidity: grams of tartaric acid per cubic decimeter.\n",
    "- volatile acidity: grams of acetic acid per cubic decimeter.\n",
    "- citric acid: grams of citric acid per cubic decimeter.\n",
    "- residual sugar: grams of residual sugar per cubic decimeter.\n",
    "- chlorides: grams of sodium chloride per cubic decimeter.\n",
    "- free sulfur dioxide: grams of unreacted sulfur dioxide per cubic decimeter.\n",
    "- total sulfur dioxide: grams of total sulfur dioxide per cubic decimeter.\n",
    "- density: density of the wine in grams per cubic decimeter.\n",
    "- pH: pH value of the wine\n",
    "- sulphates: grams of potassium sulphate per cubic decimeter\n",
    "- alcohol : percentage volume of alcohol content.\n",
    "- quality : integer range from 0 (representing low-quality) to 10 (representing high-quality)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad4143-f93e-438f-8a88-0fd4ca0dd967",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344514c-1dac-4142-9e0e-5b256a53d5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c21552-ed99-4765-baef-f84875244308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0c69e-cb76-4768-8dbe-f95f510be63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbd917-569a-419c-9070-811fde1078f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352f9fb-c339-40c7-98ea-5ef087b8dfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16e513-54dc-406c-8e1c-3517b2ba8064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c0062c-a50e-47aa-a130-ecda8b5af736",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0219f2d7-2427-4578-b2cb-de8a326360b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our X and Y data\n",
    "X = df.drop('quality', axis=1) \n",
    "y = df['quality']\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53654f08-11da-4caf-94c1-bd83aa6903f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Column Transformer\n",
    "numeric_features = list(X.columns)\n",
    "\n",
    "preprocessor = make_column_transformer((StandardScaler(), numeric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2576bea-0409-4d9c-87ad-ba654e99b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to return accuracy of from each trained model\n",
    "def cross_val_scores(model, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Returns mean accuracy from 5-fold cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        values for features from training data\n",
    "    y_train : numpy array or pandas Series\n",
    "        values for target from training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with all mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv = 5, \n",
    "                            return_train_score = True\n",
    "                            )\n",
    "    \n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    result_scores =[]\n",
    "    for i in range(len(scores)):\n",
    "        result_scores.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores.iloc[i], std_scores.iloc[i])))\n",
    "\n",
    "\n",
    "    return pd.Series(data=result_scores, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0d882bda-9064-4707-9b18-36015c971fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of model dictionary\n",
    "models = {\n",
    "    \"dummy\": DummyClassifier(),\n",
    "    \"decision tree\": DecisionTreeClassifier(),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"RBF SVM\": SVC(),\n",
    "    \"naive bayes\": GaussianNB(),\n",
    "    \"log reg\": LogisticRegression()\n",
    "}\n",
    "\n",
    "# Creation of results dictionary\n",
    "results= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e9514cdf-69ef-4491-9a23-c21a19f7c591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.004 (+/- 0.001)</td>\n",
       "      <td>0.002 (+/- 0.000)</td>\n",
       "      <td>0.425 (+/- 0.002)</td>\n",
       "      <td>0.425 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.008 (+/- 0.001)</td>\n",
       "      <td>0.002 (+/- 0.001)</td>\n",
       "      <td>0.590 (+/- 0.038)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.004 (+/- 0.001)</td>\n",
       "      <td>0.012 (+/- 0.001)</td>\n",
       "      <td>0.574 (+/- 0.018)</td>\n",
       "      <td>0.709 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>0.041 (+/- 0.003)</td>\n",
       "      <td>0.017 (+/- 0.000)</td>\n",
       "      <td>0.617 (+/- 0.027)</td>\n",
       "      <td>0.682 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive bayes</th>\n",
       "      <td>0.003 (+/- 0.001)</td>\n",
       "      <td>0.002 (+/- 0.001)</td>\n",
       "      <td>0.527 (+/- 0.059)</td>\n",
       "      <td>0.557 (+/- 0.020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log reg</th>\n",
       "      <td>0.013 (+/- 0.002)</td>\n",
       "      <td>0.001 (+/- 0.001)</td>\n",
       "      <td>0.593 (+/- 0.042)</td>\n",
       "      <td>0.607 (+/- 0.008)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fit_time         score_time         test_score  \\\n",
       "dummy          0.004 (+/- 0.001)  0.002 (+/- 0.000)  0.425 (+/- 0.002)   \n",
       "decision tree  0.008 (+/- 0.001)  0.002 (+/- 0.001)  0.590 (+/- 0.038)   \n",
       "kNN            0.004 (+/- 0.001)  0.012 (+/- 0.001)  0.574 (+/- 0.018)   \n",
       "RBF SVM        0.041 (+/- 0.003)  0.017 (+/- 0.000)  0.617 (+/- 0.027)   \n",
       "naive bayes    0.003 (+/- 0.001)  0.002 (+/- 0.001)  0.527 (+/- 0.059)   \n",
       "log reg        0.013 (+/- 0.002)  0.001 (+/- 0.001)  0.593 (+/- 0.042)   \n",
       "\n",
       "                     train_score  \n",
       "dummy          0.425 (+/- 0.000)  \n",
       "decision tree  1.000 (+/- 0.000)  \n",
       "kNN            0.709 (+/- 0.003)  \n",
       "RBF SVM        0.682 (+/- 0.008)  \n",
       "naive bayes    0.557 (+/- 0.020)  \n",
       "log reg        0.607 (+/- 0.008)  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of model pipelines and cross-evaluation\n",
    "for model_key, model in models.items():\n",
    "    model_pipeline = make_pipeline(\n",
    "        preprocessor,\n",
    "        model\n",
    "    )\n",
    "\n",
    "    results[model_key] = cross_val_scores(model_pipeline,\n",
    "                                                   X_train,\n",
    "                                                   y_train)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de900a8d-30a4-453d-970c-c9b3ea498200",
   "metadata": {},
   "source": [
    "_Table 1: Comparison of fit time, score time, testing score and validation scores for different models_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958c97d",
   "metadata": {},
   "source": [
    "From these results, it appears that the RBF SVM model gives the best validation scores. Therefore, this model will be used for hyperparameter tuning in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "06f40256-f308-4e7f-a3a7-8351360e8165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'svc__C': np.float64(1.8126674515810615), 'svc__decision_function_shape': 'ovr', 'svc__gamma': np.float64(0.6077573066429692)}\n",
      "Best cross-validation score: 0.652061887254902\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for the best performing model\n",
    "param_dist = {\n",
    "    'svc__C': loguniform(1e-3, 1e3),\n",
    "    'svc__gamma': loguniform(1e-3, 1e3),\n",
    "    'svc__decision_function_shape': ['ovr', 'ovo'] \n",
    "}\n",
    "\n",
    "svc_tuning = make_pipeline(preprocessor, SVC())\n",
    "\n",
    "random_search = RandomizedSearchCV(svc_tuning, param_dist, \n",
    "                                   n_iter=50, cv=5, n_jobs=-1) #Do we want random_state?\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best cross-validation score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f37bfb0-ccf0-4555-8f23-ff579829c0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.653125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy\n",
       "0  0.653125"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the model with the best hyperparameters on the testing set\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "test_accuracy_df = pd.DataFrame({\"accuracy\": [test_score]})\n",
    "test_accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ba3aa-4a6b-44cd-815e-b620ed6f18e2",
   "metadata": {},
   "source": [
    "_Table 2: Accuracy of model with best hyperparameters on the testing set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9550eed9-f47b-4b49-bf6e-101cb63fe46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Negative</th>\n",
       "      <td>318</td>\n",
       "      <td>308</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>275</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  3    4    5    6    7    8\n",
       "True Negative   318  308  137  137  275  314\n",
       "False Positive    0    0   45   54   11    1\n",
       "False Negative    2   12   29   43   20    5\n",
       "True Positive     0    0  109   86   14    0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-class Confusion Matrix\n",
    "labels = np.unique(y_test)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "confusion_matrix = multilabel_confusion_matrix(y_test, y_pred, labels = labels)\n",
    "\n",
    "columns = [\"True Negative\", \"False Positive\", \"False Negative\", \"True Positive\"]\n",
    " \n",
    "# Create a DataFrame with proper column names and labels\n",
    "conf_matrix_df = pd.DataFrame(confusion_matrix.reshape(len(labels), -1), index=labels, columns=columns).T\n",
    "conf_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70e9f2-fb70-45fe-97a6-c5b7b643d2e1",
   "metadata": {},
   "source": [
    "_Table 3: Confusion matrix of test data_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba5d3a-032e-4b7c-9105-2190084c9611",
   "metadata": {},
   "source": [
    "## Discussion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8009a2-3fd2-4fdc-bee6-fb1bb4d2bd2b",
   "metadata": {},
   "source": [
    "summarize what you found\n",
    "\n",
    "discuss whether this is what you expected to find?\n",
    "\n",
    "discuss what impact could such findings have?\n",
    "\n",
    "discuss what future questions could this lead to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e231e2-df72-4133-85c3-be755963d7d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0517c784-2fe7-49ec-b19b-d56d3e72256e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92aef121",
   "metadata": {},
   "source": [
    "From the process of selecting an appropriate model, 5-fold cross validation was done on each model, using the training data. The validation scores (accuracy) of each model was assessed and the Support Vector Classifier (SVC) with RBF Kernel resulted in the best score. There was a large amountobserved overfitting on the training data with the Decision Tree model. The k-Nearest Neighbours, Naive Bayes and Logistic Regression all yielded similar validation scores, with the Naive Bayes model performing the worst.\n",
    "\n",
    "\n",
    "Even though the SVC RBF model gave the best accuracy, it also have the longest fit-time and score-time. The impact of this is that predictions on a large number of value could take a long time, and depending on the scenario may not be ideal. In this case, efficiency is not a great concern, but this should be noted for future use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b82bcd-4f5e-47f9-817c-19f06b3e08a1",
   "metadata": {},
   "source": [
    "An average accuracy of ~0.6 for both testing and validation will bring some issues for future questions. These questions include: \n",
    "* Will using a different kernel for the SVC yield greater performance?\n",
    "* If some features are excluded or more chemical features are added, will performance differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435aac5d-1e83-46ec-9750-cccde0771812",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c0463-112a-4430-b952-acd262dccfde",
   "metadata": {},
   "source": [
    "Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. Decision Support Systems, 47(4), 547-553. Retrieved from http://www3.dsi.uminho.pt/pcortez/wine/\n",
    "\n",
    "UCI Machine Learning Repository. (n.d.). Wine quality dataset. Retrieved from https://archive.ics.uci.edu/dataset/186/wine+quality\n",
    "\n",
    "Cortez, P., & Cerdeira, A. (2009). Modeling wine preferences by data mining from physicochemical properties. Retrieved from https://www.semanticscholar.org/paper/Modeling-wine-preferences-by-data-mining-from-Cortez-Cerdeira/bf15a0ccc14ac1deb5cea570c870389c16be019c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f9189-14c4-4d84-8574-0a5ee33ed61c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:522_group1] *",
   "language": "python",
   "name": "conda-env-522_group1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
